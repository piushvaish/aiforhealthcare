{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "\n",
    "import skimage\n",
    "from skimage import io\n",
    "import glob\n",
    "\n",
    "import sklearn\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we'll do background segmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in two mammo images: \n",
    "dense = io.imread('dense/mdb003.pgm')\n",
    "fatty = io.imread('fatty/mdb005.pgm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fatty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = plt.hist(dense.ravel(),bins=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = plt.hist(fatty.ravel(),bins=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Next, experiment with different cut-off intensity thresholds to try to separate the background of the image\n",
    "## From the histograms above, we might want to start with zero: \n",
    "\n",
    "thresh = 50\n",
    "\n",
    "dense_bin = (dense > thresh) * 255\n",
    "fatty_bin = (fatty > thresh) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dense_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fatty_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with different values of 'thresh' above until you are satisfied that you are able to create a reasonable separation of tissue from background.\n",
    "\n",
    "One image pre-processing trick you might try before binarizing is _smoothing_ which you perform with a gaussian filter. Try adding the following step before binarization: \n",
    "\n",
    "img_smooth = gaussian_filter(img, sigma = 5)\n",
    "\n",
    "Where changing the value of _sigma_ will change the amount of smoothing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Once you have chosen your value of threshold, let's use it to see if we can classify dense v. fatty breast tissue: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's first get all of the intensity values of the breast tissue for our fatty breast images using the\n",
    "## segmentation method above: \n",
    "thresh = 50\n",
    "\n",
    "fatty_imgs = glob.glob(\"fatty/*\")\n",
    "dense_imgs = glob.glob(\"dense/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fatty_intensities = []\n",
    "\n",
    "for i in fatty_imgs: \n",
    "    \n",
    "    img = plt.imread(i)\n",
    "    img_mask = (img > thresh)\n",
    "    fatty_intensities.extend(img[img_mask].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = plt.hist(fatty_intensities,bins=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_intensities = []\n",
    "\n",
    "for i in dense_imgs: \n",
    "    \n",
    "    img = plt.imread(i)\n",
    "    img_mask = (img > thresh)\n",
    "    dense_intensities.extend(img[img_mask].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = plt.hist(dense_intensities,bins=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.mode(fatty_intensities)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.mode(dense_intensities)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in fatty_imgs: \n",
    "    \n",
    "    img = plt.imread(i)\n",
    "    img_mask = (img > thresh)\n",
    "    \n",
    "    fatty_delta = scipy.stats.mode(img[img_mask])[0][0] - scipy.stats.mode(fatty_intensities)[0][0]\n",
    "    dense_delta = scipy.stats.mode(img[img_mask])[0][0] - scipy.stats.mode(dense_intensities)[0][0]\n",
    "    \n",
    "    if (np.abs(fatty_delta) < np.abs(dense_delta)):\n",
    "        print(\"Fatty\")\n",
    "    else:\n",
    "        print(\"Dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dense_imgs: \n",
    "    \n",
    "    img = plt.imread(i)\n",
    "    img_mask = (img > thresh)\n",
    "    \n",
    "    fatty_delta = scipy.stats.mode(img[img_mask])[0][0] - scipy.stats.mode(fatty_intensities)[0][0]\n",
    "    dense_delta = scipy.stats.mode(img[img_mask])[0][0] - scipy.stats.mode(dense_intensities)[0][0]\n",
    "    \n",
    "    if (np.abs(fatty_delta) < np.abs(dense_delta)):\n",
    "        print(\"Fatty\")\n",
    "    else:\n",
    "        print(\"Dense\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just by using this method, we're able to get 100% accuracy on dense images and 70% accuracy on fatty images! Now, we 'trained' on the same set of images that we validated on, so in order to be confident in this algorithm we need to validated on a separate held out set, which we'll learn about in the next lesson. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
